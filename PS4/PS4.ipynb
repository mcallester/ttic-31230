{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pa4Z_RwvQOxd"
   },
   "source": [
    "# Instructions\n",
    "\n",
    "As in the previous assignment, youl'll be using PyTorch instead of EDF. This assignment will focus on generative modelling, and you'll implement and train a VAE and a GAN.\n",
    "\n",
    "It is highly suggested to use google colab and run the notebook on a GPU node.\n",
    "Check https://colab.research.google.com/ and look for tutorials online on how to use it. To use a GPU go to Runtime -> Change runtime type and select GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ZjnJPFe1xB7"
   },
   "outputs": [],
   "source": [
    "import torch, math, copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from scipy.stats import kde\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6x1bZGhRRh7h"
   },
   "source": [
    "We'll start by coding up a toy problem and seeing how a VAE and a GAN behave on it. Consider the following stochastic process:\n",
    "$$ \\mu_x \\sim U(\\{1,2,3\\})$$\n",
    "$$ \\mu_y \\sim U(\\{1,2,3\\})$$\n",
    "$$ s \\sim \\mathcal N \\left([\\mu_x, \\mu_y], \\frac{1}{100}I \\right)$$\n",
    "where $I$ is the $2 \\times 2$ identity matrix.\n",
    "\n",
    "Implement the function in the next cell such that it returns $n$ samples distributed as $s$ from the above process. The returned object should be a $n \\times 2$ PyTorch tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qZXaLONN1xB9"
   },
   "outputs": [],
   "source": [
    "def sample(n):\n",
    "    s = # implementation goes here\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhQErUjgTri-"
   },
   "source": [
    "Now we'll sample 1000 points and see how they are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qY5MDlKn1xB-"
   },
   "outputs": [],
   "source": [
    "def plot_density(data):\n",
    "    data = data.numpy()\n",
    "    nbins = 50\n",
    "    x, y = data.T\n",
    "    k = kde.gaussian_kde(data.T)\n",
    "    xi, yi = np.mgrid[x.min():x.max():nbins*1j, y.min():y.max():nbins*1j]\n",
    "    zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    "    \n",
    "    plt.pcolormesh(xi, yi, zi.reshape(xi.shape), shading='gouraud', cmap=plt.cm.BuGn_r)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "gYbaj-3N1xB-",
    "outputId": "09284ce7-faf4-48a8-cd99-c238337b302c"
   },
   "outputs": [],
   "source": [
    "data = sample(1000)\n",
    "plot_density(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUvTVQiw1xB-"
   },
   "source": [
    "## VAE on a Toy Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1lW8h9x-VXsf"
   },
   "source": [
    "Recall that when training a VAE we're concerned with the following problem:\n",
    "\n",
    "$$\\min_{\\phi} \\,\\ \\mathbb E_{x \\sim Pop, z \\sim P_\\phi(z|x)} \\left[ \\ln \\frac{P_\\phi(z|x)}{P(z)} - \\ln P_\\phi(x|z) \\right] \\,.$$\n",
    "\n",
    "We'll model $P_\\phi(z|x)$ with an encoder and $P_\\phi(x|z)$ with a decoder as follows:\n",
    "$$P_\\phi(z|x) = \\mathcal N \\left(\\mu_{\\phi,z}(x), \\Sigma_{\\phi,z}(x) \\right)$$\n",
    "$$P_\\phi(x|z) = \\mathcal N \\left( \\mu_{\\phi,x}(z), \\sigma^2 I \\right) \\,,$$\n",
    "where $\\mu_{\\phi,z}, \\Sigma_{\\phi,z}, \\mu_{\\phi,x}$ are neural networks, and $\\Sigma_{\\phi,z}(x)$ is diagonal.\n",
    "\n",
    "Moreover, let $P(z)$ (the prior over $z$) to be $\\mathcal N(0, I)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oc4-AXKEZ0aR"
   },
   "source": [
    "**<span style=\"color:blue\">\n",
    "    For the above distributions, what is $\\ln P_\\phi(x|z)$ as a function of $x, z, \\mu_{\\phi,x}$, and $\\sigma$?\n",
    "</span>**\n",
    "\n",
    "**<span style=\"color:red\">\n",
    "    ------------------------------------------------------------------------------- ANSWER (BEGIN) -------------------------------------------------------------------------------\n",
    "</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3uYiJSoaqcE"
   },
   "source": [
    "**<span style=\"color:red\">\n",
    "    ------------------------------------------------------------------------------- ANSWER (END) -------------------------------------------------------------------------------\n",
    "</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tToMRDPnbHw5"
   },
   "source": [
    "**<span style=\"color:blue\">\n",
    "    For the above distributions, what is $\\ln \\frac{P_\\phi(z|x)}{P(z)}$ as a function of $x, z, \\mu_{\\phi,z}, \\Sigma_{\\phi,z}$?\n",
    "</span>**\n",
    "\n",
    "**<span style=\"color:red\">\n",
    "    ------------------------------------------------------------------------------- ANSWER (BEGIN) -------------------------------------------------------------------------------\n",
    "</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eq37ceGebIOx"
   },
   "source": [
    "**<span style=\"color:red\">\n",
    "    ------------------------------------------------------------------------------- ANSWER (END) -------------------------------------------------------------------------------\n",
    "</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjKQmGX2cDQP"
   },
   "source": [
    "We are almost ready to set up a VAE network in PyTorch and train it. The following cell has an incomplete implementation of a VAE. The encoder and decoder networks are already defined (note that the encoder outputs $\\log \\Sigma$ instead of $\\Sigma$, which is standard practice since otherwise we have to guarantee that the covariance matrix is non-negative). latent_dim is the dimensionality of the latent variable $z$.\n",
    "\n",
    "Complete the implementations of encode, sample, and decode.\n",
    "The encode method receives samples $x$ and has to return the mean vector $\\mu_z(x)$ and the element-wise log of the diagonal of $\\Sigma_z(x)$. The self.encoder network already maps $x$ to a 50-dim vector, and the self.mu, self.logvar modules can be used to map this 50-dim vector to the mean vector and the log diag of the covariance matrix.\n",
    "\n",
    "The sample method receives mu and logvar (the outputs of encode) and has to return samples from the corresponding Gaussian distribution. Here we typically employ the reparameterization trick, where we can draw a sample $s \\sim \\mathcal N(\\mu, \\sigma)$ by doing $s = \\mu + \\sigma \\cdot \\epsilon, \\epsilon \\sim \\mathcal N(0, 1)$, which yields well-defined gradients that autograd takes care of computing.\n",
    "\n",
    "Finally, the decode method takes $z$ as input and should return $\\mu_x(z)$. You should use the self.decodet module for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "chToiTtj1xB-"
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(2, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 50),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.mu = nn.Linear(50, latent_dim)\n",
    "        self.logvar = nn.Linear(50, latent_dim)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 2)\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        # implementation goes here\n",
    "        return mu, logvar\n",
    "    \n",
    "    def sample(self, mu, logvar):\n",
    "        # implementation goes here\n",
    "        return z\n",
    "    \n",
    "    def decode(self, z):\n",
    "        # implementation goes here\n",
    "        return out\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.sample(mu, logvar)\n",
    "        out = self.decode(z)\n",
    "        return mu, logvar, out\n",
    "    \n",
    "    def generate(self, n):\n",
    "        z = torch.randn(n, self.latent_dim).cuda()\n",
    "        samples = self.decode(z)\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpohLOwXghjv"
   },
   "source": [
    "Finally, implement the loss of the VAE by using the equations you derived previously. The recon_loss term should have the factor corresponding to $P(x|z)$, while kld_loss should have the KL divergence term.\n",
    "\n",
    "In your derivation $\\sigma$ hopefully showed up as a weight between the two terms. Here we'll use the standard beta-VAE notation and apply a weight beta on the KL divergence term instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ufwdoR-n1xB_"
   },
   "outputs": [],
   "source": [
    "def loss(x, out, mu, logvar, beta):\n",
    "    recons_loss = # implementation goes here \n",
    "    kld_loss = # implementation goes here\n",
    "    loss = recons_loss + beta * kld_loss\n",
    "    return recons_loss, kld_loss, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beQga_rYg-n7"
   },
   "source": [
    "We can then train the VAE on the toy problem and see how it performs.\n",
    "Try different values of beta until you find one that yields good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rbt05gKO1xB_"
   },
   "outputs": [],
   "source": [
    "vae = VAE(100).cuda()\n",
    "opt = torch.optim.Adam(vae.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xxwoFc941xB_"
   },
   "outputs": [],
   "source": [
    "beta = 1.0\n",
    "for i in range(20000):\n",
    "    s = sample(128).cuda()\n",
    "    mu, logvar, out = vae(s)\n",
    "    rl, kl, l = loss(s, out, mu, logvar, beta)\n",
    "    opt.zero_grad()\n",
    "    l.backward()\n",
    "    opt.step()\n",
    "    if i % 1000 == 0:\n",
    "        data = vae.generate(5000)\n",
    "        plot_density(data.cpu().data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:blue\">\n",
    "    How does beta affect the performance of the VAE? Show or discuss what tradeoff beta controls, and how this can be observed from the above plots and/or any additional plots.\n",
    "</span>**\n",
    "\n",
    "**<span style=\"color:red\">\n",
    "    ------------------------------------------------------------------------------- ANSWER (BEGIN) -------------------------------------------------------------------------------\n",
    "</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">\n",
    "    ------------------------------------------------------------------------------- ANSWER (END) -------------------------------------------------------------------------------\n",
    "</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_AhuaNbe1xCA"
   },
   "source": [
    "## GAN\n",
    "\n",
    "Recall the GAN objective\n",
    "$$\\min_\\psi \\max_\\phi \\,\\ \\mathbb E_{x \\sim Pop}[ -\\ln P_\\psi(1 | x) ] + \\mathbb E_{z \\sim \\mathcal N(0,1)} [- \\ln P_\\psi(0|G_\\phi(z))  ] \\,,$$\n",
    "where $G_\\phi$ is a network that maps gaussian noise $z \\sim \\mathcal N(0,1)$ to $G(z)$ with the same shape as $x$, and $P_\\psi$ is modeled by another network (the discriminator) that maps real samples $x$ and 'fake' samples $G(z)$ to a distribution over $\\{0,1\\}$.\n",
    "\n",
    "We will follow the common practice of adopting a different objective for the generator network $G$:\n",
    "$$\\min_\\phi \\,\\ \\mathbb E_{z \\sim \\mathcal N(0,1)} [- \\ln P_\\psi(1|G_\\phi(z))  ] \\,.$$\n",
    "\n",
    "First, complete the implementation of the Generator module below. The forward method takes an integer $n$ as input and should return $n$ samples $G(z), z \\sim \\mathcal N(0, I)$, each with dimensionality 2. You should use the self.network module for the mapping $G$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WVvhJ7PT1xCA"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 2)\n",
    "        )\n",
    "\n",
    "    def decode(self, input):\n",
    "        out = self.network(input)\n",
    "        return out\n",
    "\n",
    "    def forward(self, n):\n",
    "        z = # implementation goes here \n",
    "        samples = # implementation goes here\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q3LbeyP41xCA"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(2, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        out = self.network(input)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q0Eekyo81xCA"
   },
   "outputs": [],
   "source": [
    "generator = Generator(100).cuda()\n",
    "gopt = torch.optim.Adam(generator.parameters(), lr=5e-4, betas=(0.5, 0.999))\n",
    "discriminator = Discriminator().cuda()\n",
    "dopt = torch.optim.Adam(discriminator.parameters(), lr=5e-4, betas=(0.5, 0.999))\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CdZxQ0AnYNB"
   },
   "source": [
    "Now, you'll implement the training procedure for GANs. In each iteration of the for loop below we'll update the parameters of the generator and then update the discriminator.\n",
    "\n",
    "Fill up the missing code below. You should rely on the objective given previously to define the loss of the generator and the discriminator (both the function, the data inputs, and the target labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jGUtMqkz1xCA",
    "outputId": "8960aca2-8e93-43bf-cf2d-9d91a142a870"
   },
   "outputs": [],
   "source": [
    "for i in range(20000):\n",
    "    # Train G\n",
    "    \n",
    "    # implementation goes here\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Train D\n",
    "    \n",
    "    # implementation goes here\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        data = generator(5000)\n",
    "        plot_density(data.cpu().data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ICCuztvoFJf"
   },
   "source": [
    "**<span style=\"color:blue\">\n",
    "    Compare and discuss the results you obtained with the VAE and with the GAN approach.\n",
    "</span>**\n",
    "\n",
    "**<span style=\"color:red\">\n",
    "    ------------------------------------------------------------------------------- ANSWER (BEGIN) -------------------------------------------------------------------------------\n",
    "</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NaouHwMsoUgM"
   },
   "source": [
    "**<span style=\"color:red\">\n",
    "    ------------------------------------------------------------------------------- ANSWER (END) -------------------------------------------------------------------------------\n",
    "</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emI0y4fh4DXL"
   },
   "source": [
    "## VAE and GANs on CelebA/MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwg7bM9QoYrY"
   },
   "source": [
    "In this second part of the assignment you'll train a VAE and a GAN on a more interesting dataset. The cell below will try to download and load CelebA, and will just load MNIST in case there is an error.\n",
    "\n",
    "It is likely that you'll get an error when trying to download CelebA since the its google drive is always out of quota. If you'd like to use CelebA anyway, you can try to download it from here http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html or some other source. If you're not running this notebook on a GPU then use MNIST instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j79_U6cf1xCA"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Resize(64), transforms.CenterCrop(64), transforms.Normalize((0.5,), (0.5,))])\n",
    "try:\n",
    "    dataset = datasets.CelebA(\"data\", split='all', download=True, transform=transform)\n",
    "except:\n",
    "    dataset = datasets.MNIST(\"data\", train=True, download=True, transform=transform)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use a a CNN for the VAE instead of the simple model we defined previously.\n",
    "Implement a network following these specifications:\n",
    "\n",
    "- Encoder. Should have 4 conv layers, each with kernel size 4, stride 2 and padding 1, which decrease the spatial resolution by half. The output of the 4th conv (a spatial res. 4x4) should be flattened and then fully connected layers should be used to compute mu and logvar. Add whichever activation function you prefer between the conv layers (ReLU, LeakyReLU, ELU, etc), and feel free to add batch norm as well. Let the first conv layer have, say, 8 or 16 channels and then double the number of channels at each following conv layer.\n",
    "\n",
    "- Decoder. Try to have an architecture that is roughly symmetric to the encoder. For example, start with a fully connected layer to project the latent_dim dimensional input such that you end up wuth a (128*4*4)-dimensional vector that you can reshape into a 4x4 image. Then you can apply 4 transposed conv layers, e.g. with kernel size 4, stride 2 and padding 1, to double the spatial resolution with each layer, having a final output of size 64x64. Start with around 64 or 128 channels for the first transposed conv and then halve the number of channels at each following conv layer. As before, add your preferred activation function between layers, with or without batch norm.\n",
    "\n",
    "The encode, sample, and decode methods have the same specification as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pU91oCU61xCA"
   },
   "outputs": [],
   "source": [
    "class ConvVAE(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(ConvVAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            # implementation goes here\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            # implementation goes here\n",
    "        )\n",
    "        \n",
    "    def encode(self, input):\n",
    "        # implementation goes here\n",
    "        return mu, logvar\n",
    "    \n",
    "    def sample(self, mu, logvar):\n",
    "        # implementation goes here\n",
    "        return eps * std + mu\n",
    "    \n",
    "    def decode(self, input):\n",
    "        # implementation goes here\n",
    "        return out\n",
    "        \n",
    "    def forward(self, input):\n",
    "        mu, logvar = self.encode(input)\n",
    "        z = self.sample(mu, logvar)\n",
    "        out = self.decode(z)\n",
    "        return mu, logvar, out\n",
    "    \n",
    "    def generate(self, n):\n",
    "        z = torch.randn(n, self.latent_dim).cuda()\n",
    "        samples = self.decode(z)\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XXxcwb_U6ClA"
   },
   "outputs": [],
   "source": [
    "vae = ConvVAE(100).cuda()\n",
    "opt = torch.optim.Adam(vae.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below applies a 'patch' in case you're using google colab (cv2_imshow doesn't work properly on google colab without it). Feel free to comment out the first import if you're not using google colab (you might have to add from cv2 import cv2_imshow, though)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c15YX5GvBp-R"
   },
   "outputs": [],
   "source": [
    "from google.colab.patches import cv2_imshow\n",
    "import cv2\n",
    "\n",
    "def show(x):\n",
    "    img = x.data.cpu().permute(1, 2, 0).numpy() * 255\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    cv2_imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, try to find a value for beta that yields reasonable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oguvCNNV6E5b"
   },
   "outputs": [],
   "source": [
    "beta = 1.0\n",
    "for epoch in range(100):\n",
    "    for i, x in enumerate(loader):\n",
    "        if len(x) == 2:\n",
    "            x = x[0]\n",
    "        x = x.cuda()\n",
    "        \n",
    "        mu, logvar, out = vae(x)\n",
    "        rl, kl, l = loss(x, out, mu, logvar, beta)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        l.backward()\n",
    "        opt.step()\n",
    "        if i == 0:\n",
    "            vae.eval()\n",
    "            data = vae.generate(8)\n",
    "            grid_img = torchvision.utils.make_grid(data, nrow=8, normalize=True)\n",
    "            show(grid_img)\n",
    "            vae.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll also re-implement the Generator and Discriminator modules for the GAN, adopting a CNN-like architecture.\n",
    "\n",
    "For the generator, implement a network similar to the one you used for the VAE decoder (fully connected for projection followed by 4 transposed convolutions), while for the discriminator you should use a network similar to the VAE encoder (4 conv layers with stride 2, but note that the output should be a scalar per image, not a latent vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KvOE5m9vNLrR"
   },
   "outputs": [],
   "source": [
    "class ConvGenerator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(ConvGenerator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            # implementation goes here\n",
    "        )\n",
    "    \n",
    "    def decode(self, input):\n",
    "        out = # implementation goes here\n",
    "        return out\n",
    "\n",
    "    def forward(self, n):\n",
    "        z = torch.randn(n, self.latent_dim).cuda()\n",
    "        samples = self.decode(z)\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B0aJNT5NNXKt"
   },
   "outputs": [],
   "source": [
    "class ConvDiscriminator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(ConvDiscriminator, self).__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            # implementation goes here\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        out = # implementation goes here\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XWV-Q1k0OGfE"
   },
   "outputs": [],
   "source": [
    "generator = ConvGenerator(100).cuda()\n",
    "gopt = torch.optim.Adam(generator.parameters(), lr=5e-4, betas=(0.5, 0.999))\n",
    "discriminator = ConvDiscriminator(100).cuda()\n",
    "dopt = torch.optim.Adam(discriminator.parameters(), lr=5e-4, betas=(0.5, 0.999))\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 868
    },
    "id": "QkWAtlqMOLDG",
    "outputId": "9ac41412-77e6-491c-cd63-2723f0cb3123"
   },
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "    for i, x in enumerate(loader):\n",
    "        if len(x) == 2:\n",
    "            x = x[0]\n",
    "        x = x.cuda()\n",
    "\n",
    "        # Train G\n",
    "        \n",
    "        # implementation goes here\n",
    "        \n",
    "        \n",
    "        # Train D\n",
    "        \n",
    "        # implementation goes here\n",
    "        \n",
    "        if i == 0:\n",
    "            grid_img = torchvision.utils.make_grid(fake[:8], nrow=8, normalize=True)\n",
    "            show(grid_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:blue\">\n",
    "    Compare and discuss the results you obtained with the VAE and with the GAN approach for this new dataset. Which of the two approaches was able to generate more realistic samples? Which of the two did you feel that you understood better (there is no correct answer here), and why? Mention one advantage and disadvantage of each of the two methods -- these should be precise properties about each approach, with a focus on what each method can and cannot do. Feel free to check papers, the original GAN paper might be especially helpful.\n",
    "</span>**\n",
    "\n",
    "**<span style=\"color:red\">\n",
    "    ------------------------------------------------------------------------------- ANSWER (BEGIN) -------------------------------------------------------------------------------\n",
    "</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">\n",
    "    ------------------------------------------------------------------------------- ANSWER (END) -------------------------------------------------------------------------------\n",
    "</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "PS4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
