\input ../../SlidePreamble
\input ../../preamble

\begin{document}

{\Huge
  \centerline{\bf TTIC 31230, Fundamentals of Deep Learning}
  \bigskip
  \centerline{David McAllester, Autumn 2020}
  \vfill
  \centerline{\bf Stochastic Gradient Descent (SGD)}
  \vfill
  \centerline{\bf and Stochastic Differential Equations (SDEs)}
  \vfill
  \vfill
  \vfill

\slide{Modeling the SGD as a Stochastic Process}

If we randomly select training points then SGD is a stochastic process.

\vfill
Can we analytically solve for stationary distributions?

\vfill
Is the stationary distribution Gibbs --- is it $\frac{1}{Z}e^{-\frac{{\cal L}}{kT}}$ where the temperature $T$ is determined by the learning rate?


\slide{Modeling the SGD as a Stochastic Process}

It is possible to model both the stationary distribution and non-stationary stochastic dynamics
with a {\color{red} continuous time} stochastic differential equation such as {\color{red} Brownian motion}
or {\color{red} Langevin Dynamics}.

\vfill
Langevin Dynamics is the special case where the stationary distribution is Gibbs.

\vfill
We will show here that in general the stationary distribution of SGD is not Gibbs and hence does not correspond to Langevin dynamics.

\slide{Holding $\eta$ Fixed}


\vfill
Consider SGD with batch size 1.

$$\Phi_{i+1} = \Phi_i - \eta\hat{g}_i$$

\vfill
Unlike gradient flow, we now hold $\eta > 0$ fixed.

\vfill
We will still take ``time'' to be the sum of the learning rates over the updates.

\vfill
For $N$ steps of SGD we define $\Delta t = N \eta$

\slide{Holding $\eta$ Fixed}

We consider $\Delta t$ large enough so that $\Delta t$ corresponds to many SGD updates.

\vfill
We consider $\Delta t$ small enough so that the gradient estimate distribution does not change over the interval $\Delta t$.

\slide{Applying the Law of Large Numbers}

If the mean gradient $g(\Phi)$ is approximately constant over the interval $\Delta t = N \eta$ we have

$$\Phi(t + \Delta t)  \approx \Phi(t) -g(\Phi)\Delta t + \eta \sum_{i=1}^N (g(\Phi) - \hat{g}_i)$$

\vfill
The random variables in the last term have zero mean.

\vfill
By the law of large numbers a sum (not the average) of $N$ random vectors will approximate a Gaussian distribution where the standard deviation
grows like $\sqrt{N}$.

\slide{Applying the Law of Large Numbers}

For $\epsilon \sim {\cal N}(0,\Sigma)$
where $\Sigma$ is the covariance matrix of the random variable $\hat{g}$ we have

\begin{eqnarray*}
\Phi(t + \Delta t) & \approx & \Phi(t) -g(\Phi)\Delta t + \eta \sum_{j=1}^N (g(\Phi) - \hat{g}_i) \\
\\
& \approx & \Phi(t) -g(\Phi)\Delta t + \eta \epsilon \sqrt{N} \\
\\
& = & \Phi(t) -g(\Phi)\Delta t + \eta \epsilon \sqrt{\frac{\Delta t}{\eta}}
\end{eqnarray*}


\slide{The Stochastic Differential Equation (SDE)}

\begin{eqnarray*}
\Phi(t + \Delta t) & \approx & \Phi(t) -g(\Phi)\Delta t + \epsilon \sqrt{{\color{red} \eta}\Delta t}\;\;\;\;\;\; \epsilon \sim {\cal N}(0,\Sigma) \\
\\
& = & \Phi(t) -g(\Phi)\Delta t + \epsilon \sqrt{\Delta t}\;\;\;\;\;\; \epsilon \sim {\cal N}(0,{\color{red} \eta}\Sigma)
\end{eqnarray*}

\vfill
We can take this last equation to hold in the limit of arbitrarily small $\Delta t$ in which case we get a continuous time stochastic process.  This process can be written as

{\color{red} $$d\Phi =  -g(\Phi)dt + \epsilon \sqrt{dt}\;\;\;\;\;\; \epsilon \sim {\cal N}(0,\eta\Sigma)$$}

\slide{The Stochastic Differential Equation}

{\color{red} $$d\Phi =  -g(\Phi)dt + \epsilon \sqrt{dt}\;\;\;\;\;\; \epsilon \sim {\cal N}(0,\eta\Sigma)$$}

\vfill
For $g(\Phi) = 0$ and $\Sigma = I$ we get Brownian motion.

\vfill
For a general loss function and $\Sigma = I$ we get Langevin Dynamics and a Gibbs stationary distribution.

\vfill
But in general we do not have $\Sigma = I$.


\slide{END}
\end{document}
